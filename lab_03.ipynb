{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# Lab 3: Save and Load Models\n",
    "\n",
    "In this notebook, we'll complete the final step of our PyTorch workflow — saving a trained model to disk and loading it back for future use. This is essential for deploying models or continuing work later."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-1",
   "metadata": {},
   "source": [
    "## Install Dependencies\n",
    "\n",
    "Run this cell to install the required libraries. We need PyTorch for model operations and `pathlib` (built-in) for file path handling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu\n",
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-3",
   "metadata": {},
   "source": [
    "## Setup from Labs 1 and 2\n",
    "\n",
    "Before we can save a model, we need a trained model. Let's quickly recreate everything from Labs 1 and 2.\n",
    "\n",
    "**From Lab 1 (Data and Model Building):**\n",
    "- Create synthetic data using `y = 0.4 * X + 0.1`\n",
    "- Split into 80% training and 20% testing sets\n",
    "- Define `LinearRegressionModel` class with learnable `weight` and `bias` parameters\n",
    "\n",
    "**From Lab 2 (Training Loop):**\n",
    "- Set up loss function (`nn.L1Loss`) and optimizer (`SGD` with lr=0.01)\n",
    "- Train for 100 epochs using the 5-step training loop\n",
    "- Model learns to approximate `weight ≈ 0.4` and `bias ≈ 0.1`\n",
    "\n",
    "![Linear Model](https://raw.githubusercontent.com/poridhiEng/lab-asset/7008e578e0c9c57813d1b267134700911793d762/tensorcode/Deep-learning-with-pytorch/LinearRegression/lab-02/images/linear-model.svg)\n",
    "\n",
    "The model takes input X, multiplies it by weights, adds bias, and outputs predictions. After training, it should discover `weight ≈ 0.4` and `bias ≈ 0.1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from pathlib import Path\n",
    "\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Target parameters (what we want the model to learn)\n",
    "weight = 0.4\n",
    "bias = 0.1\n",
    "\n",
    "# Create data\n",
    "X = torch.arange(0, 1, 0.02).unsqueeze(dim=1)\n",
    "y = weight * X + bias\n",
    "\n",
    "# Train/test split (80/20)\n",
    "train_split = int(0.8 * len(X))\n",
    "X_train, y_train = X[:train_split], y[:train_split]\n",
    "X_test, y_test = X[train_split:], y[train_split:]\n",
    "\n",
    "# Model definition\n",
    "class LinearRegressionModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.weight = nn.Parameter(torch.randn(1), requires_grad=True)\n",
    "        self.bias = nn.Parameter(torch.randn(1), requires_grad=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.weight * x + self.bias\n",
    "\n",
    "# Create model instance\n",
    "model = LinearRegressionModel()\n",
    "\n",
    "print(f\"Training samples: {len(X_train)}, Test samples: {len(X_test)}\")\n",
    "print(f\"Initial parameters: weight={model.weight.item():.4f}, bias={model.bias.item():.4f}\")\n",
    "print(f\"Target parameters:  weight={weight}, bias={bias}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-5",
   "metadata": {},
   "source": [
    "## Train the Model\n",
    "\n",
    "We'll quickly train the model using the 5-step training loop from Lab 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create loss function and optimizer\n",
    "loss_fn = nn.L1Loss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "# Training loop\n",
    "epochs = 100\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    \n",
    "    # 1. Zero gradients\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # 2. Forward pass\n",
    "    y_pred = model(X_train)\n",
    "    \n",
    "    # 3. Calculate loss\n",
    "    loss = loss_fn(y_pred, y_train)\n",
    "    \n",
    "    # 4. Backward pass\n",
    "    loss.backward()\n",
    "    \n",
    "    # 5. Update parameters\n",
    "    optimizer.step()\n",
    "    \n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"Epoch {epoch:3d} | Loss: {loss:.4f}\")\n",
    "\n",
    "print(f\"\\nTraining complete!\")\n",
    "print(f\"Learned parameters: weight={model.weight.item():.4f}, bias={model.bias.item():.4f}\")\n",
    "print(f\"Target parameters:  weight={weight}, bias={bias}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-7",
   "metadata": {},
   "source": [
    "## 1. Understanding state_dict()\n",
    "\n",
    "The `state_dict()` is a Python dictionary that maps each layer/parameter name to its tensor value. It contains all the learnable parameters of your model — in our case, just `weight` and `bias`.\n",
    "\n",
    "This is what we save to disk and load back later. By saving only the `state_dict()` (not the entire model), we keep our saved files small and portable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the state dict\n",
    "print(\"Model state_dict():\")\n",
    "print(model.state_dict())\n",
    "\n",
    "print(\"\\nBreaking it down:\")\n",
    "for param_name, param_value in model.state_dict().items():\n",
    "    print(f\"  {param_name}: {param_value.item():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-9",
   "metadata": {},
   "source": [
    "## 2. Create a Models Directory\n",
    "\n",
    "It's good practice to organize saved models in a dedicated folder. This keeps your project clean and makes it easy to find model files later.\n",
    "\n",
    "We use Python's `pathlib.Path` for cross-platform compatibility — it handles file paths correctly on Windows, Mac, and Linux."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create models directory\n",
    "MODEL_PATH = Path(\"models\")\n",
    "MODEL_PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"Model directory created: {MODEL_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-11",
   "metadata": {},
   "source": [
    "## 3. Define the Save Path\n",
    "\n",
    "We use `.pth` or `.pt` extension for PyTorch model files. This is a convention (not required) that helps identify PyTorch models at a glance.\n",
    "\n",
    "Common naming patterns: `model_name.pth`, `model_v1.pt`, `best_model.pth`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model filename and full path\n",
    "MODEL_NAME = \"linear_regression_model.pth\"\n",
    "MODEL_SAVE_PATH = MODEL_PATH / MODEL_NAME\n",
    "\n",
    "print(f\"Model will be saved to: {MODEL_SAVE_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-13",
   "metadata": {},
   "source": [
    "## 4. Save the Model\n",
    "\n",
    "We save only the `state_dict()`, not the entire model object. This is the **recommended approach** because:\n",
    "\n",
    "- **Portable**: Works even if you rename classes or move files\n",
    "- **Flexible**: Can load into modified model architectures (if compatible)\n",
    "- **Smaller files**: Only stores the essential parameter values\n",
    "\n",
    "The alternative (`torch.save(model, path)`) saves the entire model but can break if your code structure changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model state dict\n",
    "torch.save(obj=model.state_dict(), f=MODEL_SAVE_PATH)\n",
    "\n",
    "print(f\"Model saved to: {MODEL_SAVE_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-15",
   "metadata": {},
   "source": [
    "## 5. Verify the File Exists\n",
    "\n",
    "Always verify that your model was saved successfully before moving on. A quick check now can save debugging time later.\n",
    "\n",
    "We'll confirm the file exists and list all files in the models directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if file exists\n",
    "print(f\"File exists: {MODEL_SAVE_PATH.exists()}\")\n",
    "\n",
    "# List files in models directory\n",
    "print(f\"Files in {MODEL_PATH}: {list(MODEL_PATH.iterdir())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-17",
   "metadata": {},
   "source": [
    "## 6. Load the Model\n",
    "\n",
    "Loading a saved model involves three steps:\n",
    "\n",
    "1. **Create a new model instance** — This starts with random parameters (just like when we first built the model)\n",
    "2. **Load the saved state dict** — Use `torch.load()` to read the `.pth` file from disk\n",
    "3. **Apply to the model** — Use `load_state_dict()` to replace random parameters with trained ones\n",
    "\n",
    "**Important**: You must have access to the model class definition (`LinearRegressionModel`) to load the model. The saved file only contains parameter values, not the model architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Create a new model instance (with random parameters)\n",
    "loaded_model = LinearRegressionModel()\n",
    "print(f\"Before loading (random params): {loaded_model.state_dict()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Steps 2 & 3: Load the saved state dict into the model\n",
    "loaded_model.load_state_dict(torch.load(f=MODEL_SAVE_PATH))\n",
    "print(f\"After loading (trained params): {loaded_model.state_dict()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-20",
   "metadata": {},
   "source": [
    "Notice how the parameters changed from random values to the trained values after loading! The `load_state_dict()` function replaced all the random parameters with our saved trained parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-21",
   "metadata": {},
   "source": [
    "## 7. Verify Predictions Match\n",
    "\n",
    "The ultimate test: the loaded model should produce **identical predictions** to the original trained model. If predictions match, we know the save/load process preserved all the learned parameters correctly.\n",
    "\n",
    "We use `torch.allclose()` to compare tensors — it returns `True` if all values are equal (within a small tolerance for floating-point precision)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original model predictions\n",
    "model.eval()\n",
    "with torch.inference_mode():\n",
    "    original_preds = model(X_test)\n",
    "\n",
    "# Loaded model predictions\n",
    "loaded_model.eval()\n",
    "with torch.inference_mode():\n",
    "    loaded_preds = loaded_model(X_test)\n",
    "\n",
    "# Compare predictions\n",
    "predictions_match = torch.allclose(original_preds, loaded_preds)\n",
    "print(f\"Predictions match: {predictions_match}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visual comparison\n",
    "print(\"Original model predictions (first 5):\")\n",
    "print(original_preds[:5].squeeze())\n",
    "\n",
    "print(\"\\nLoaded model predictions (first 5):\")\n",
    "print(loaded_preds[:5].squeeze())\n",
    "\n",
    "print(\"\\nActual values (first 5):\")\n",
    "print(y_test[:5].squeeze())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-24",
   "metadata": {},
   "source": [
    "All predictions are identical! This confirms that our model was saved and loaded correctly. The loaded model behaves exactly like the original trained model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-25",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this lab, we learned how to:\n",
    "\n",
    "1. **Understand `state_dict()`** — the dictionary containing all model parameters\n",
    "2. **Save a trained model** using `torch.save(model.state_dict(), path)`\n",
    "3. **Load a model** by creating a new instance and calling `load_state_dict(torch.load(path))`\n",
    "4. **Verify predictions match** using `torch.allclose()`\n",
    "\n",
    "## Complete PyTorch Workflow\n",
    "\n",
    "Congratulations! You've completed the full PyTorch workflow across three labs:\n",
    "\n",
    "1. **Lab 1: Data and Model Building** — Created data and built a model with random parameters\n",
    "2. **Lab 2: Training Loop** — Implemented the 5-step training loop to learn `weight ≈ 0.4` and `bias ≈ 0.1`\n",
    "3. **Lab 3: Save and Load** — Saved the trained model and loaded it back for future use\n",
    "\n",
    "These fundamentals apply to all PyTorch projects, whether you're building simple linear regression or complex deep learning models!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
