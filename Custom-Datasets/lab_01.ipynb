{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 1: Data Preparation & Exploration\n",
    "\n",
    "In this lab, we will learn how to download, explore, and visualize custom image data for a food classification task.\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this lab, you will be able to:\n",
    "- Download and organize image datasets from external sources\n",
    "- Explore dataset structure and understand the ImageFolder format\n",
    "- Visualize individual and multiple images from the dataset\n",
    "- Analyze dataset distribution and class balance\n",
    "- Understand the importance of data exploration before model building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Setup and Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing PyTorch and setting up device-agnostic code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "print(f'PyTorch version: {torch.__version__}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f'Using device: {device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why Device-Agnostic Code?\n",
    "\n",
    "Device-agnostic code allows our model to run on **GPU** (if available) or fall back to **CPU**. This makes our code portable and efficient across different hardware configurations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Get Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First things first, we need some data.\n",
    "\n",
    "And like any good cooking show, some data has already been prepared for us.\n",
    "\n",
    "We're going to start small."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Machine learning is an **iterative process**: start small, get something working, and increase when necessary.\n",
    "\n",
    "Let's write some code to download the formatted data from GitHub.\n",
    "\n",
    "**Note:** The dataset we're about to use has been pre-formatted for what we'd like to use it for. However, you'll often have to format your own datasets for whatever problem you're working on. This is a regular practice in the machine learning world."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import zipfile\n",
    "from pathlib import Path\n",
    "\n",
    "data_path = Path('data/')\n",
    "image_path = data_path / 'pizza_steak_sushi'\n",
    "\n",
    "if image_path.is_dir():\n",
    "    print(f'{image_path} directory exists.')\n",
    "else:\n",
    "    print(f'Creating {image_path} directory...')\n",
    "    image_path.mkdir(parents=True, exist_ok=True)\n",
    "    with open(data_path / 'pizza_steak_sushi.zip', 'wb') as f:\n",
    "        request = requests.get('https://raw.githubusercontent.com/poridhioss/Introduction-to-Deep-Learning-with-Pytorch-Resources/main/Custom-Datasets/pizza_steak_sushi.zip')\n",
    "        print('Downloading data...')\n",
    "        f.write(request.content)\n",
    "    with zipfile.ZipFile(data_path / 'pizza_steak_sushi.zip', 'r') as zip_ref:\n",
    "        print('Unzipping data...')\n",
    "        zip_ref.extractall(image_path)\n",
    "    print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset downloaded!\n",
    "\n",
    "Time to become one with it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Explore the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data preparation is paramount. Before building a model, **become one with the data**. \n",
    "\n",
    "Ask yourself: *What am I trying to do here?*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before starting a project or building any kind of model, it's important to know what data you're working with.\n",
    "\n",
    "In our case, we have images of pizza, steak and sushi in **standard image classification format**.\n",
    "\n",
    "Image classification format contains separate classes of images in separate directories titled with a particular class name.\n",
    "\n",
    "For example, all images of pizza are contained in the `pizza/` directory.\n",
    "\n",
    "This format is popular across many different image classification benchmarks, including **ImageNet** (one of the most popular computer vision benchmark datasets)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal will be to take this data storage structure and turn it into a dataset usable with PyTorch.\n",
    "\n",
    "**Note:** The structure of the data you work with will vary depending on the problem you're working on. But the premise still remains: **become one with the data**, then find a way to best turn it into a dataset compatible with PyTorch.\n",
    "\n",
    "We can inspect what's in our data directory by writing a small helper function to walk through each of the subdirectories and count the files present.\n",
    "\n",
    "To do so, we'll use Python's built-in `os.walk()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def walk_through_dir(dir_path):\n",
    "    for dirpath, dirnames, filenames in os.walk(dir_path):\n",
    "        print(f'There are {len(dirnames)} directories and {len(filenames)} images in {dirpath}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "walk_through_dir(image_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What Did We Learn?\n",
    "\n",
    "From our exploration, we discovered:\n",
    "- **3 classes**: pizza, steak, and sushi\n",
    "- **Training samples**: 225 images total (75 steak + 72 sushi + 78 pizza)\n",
    "- **Test samples**: 75 images total (19 steak + 31 sushi + 25 pizza)\n",
    "- **Split ratio**: Approximately 75% train / 25% test\n",
    "\n",
    "This is enough data to get started with a simple classification model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = image_path / 'train'\n",
    "test_dir = image_path / 'test'\n",
    "print(f'Training directory: {train_dir}')\n",
    "print(f'Testing directory: {test_dir}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Excellent!\n",
    "\n",
    "That should be enough to get started."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Visualize an Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, we've seen how our directory structure is formatted.\n",
    "\n",
    "Now in the spirit of the data explorer, it's time to **visualize, visualize, visualize!**\n",
    "\n",
    "Let's write some code to:\n",
    "\n",
    "1. Get all of the image paths using `pathlib.Path.glob()` to find all of the files ending in `.jpg`\n",
    "2. Pick a random image path using Python's `random.choice()`\n",
    "3. Get the image class name using `pathlib.Path.parent.stem`\n",
    "4. Open the random image path using `PIL.Image.open()` (PIL stands for Python Image Library)\n",
    "5. Show the image and print some metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from PIL import Image\n",
    "\n",
    "random.seed(42)\n",
    "image_path_list = list(image_path.glob('*/*/*.jpg'))\n",
    "random_image_path = random.choice(image_path_list)\n",
    "image_class = random_image_path.parent.stem\n",
    "img = Image.open(random_image_path)\n",
    "\n",
    "print(f'Image path: {random_image_path}')\n",
    "print(f'Image class: {image_class}')\n",
    "print(f'Image size: {img.width}x{img.height}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can do the same with matplotlib.pyplot.imshow(), except we have to convert the image to a NumPy array first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "img_as_array = np.asarray(img)\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.imshow(img_as_array)\n",
    "plt.title(f'Class: {image_class} | Shape: {img_as_array.shape}')\n",
    "plt.axis(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Visualize Multiple Images\n",
    "\n",
    "### Why Look at Multiple Images?\n",
    "\n",
    "While examining a single image gives us basic information, viewing multiple images simultaneously provides deeper insights:\n",
    "\n",
    "- **Intra-class variability**: How different can images of the same food look? (different angles, lighting, backgrounds, plating styles)\n",
    "- **Inter-class patterns**: What visual features help distinguish one class from another?\n",
    "- **Data quality assessment**: Are all images clear and properly labeled?\n",
    "- **Edge cases**: Can we spot potentially challenging examples that might confuse our model?\n",
    "\n",
    "### Building a Visualization Helper\n",
    "\n",
    "Let's create a reusable function to display multiple random images side-by-side. This function will:\n",
    "1. Randomly sample `n` images using `random.sample()`\n",
    "2. Create a subplot grid with `matplotlib`\n",
    "3. Display each image with its class label\n",
    "4. Use `seed` parameter for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_random_images(image_path, n=3, seed=42):\n",
    "    random.seed(seed)\n",
    "    image_paths = list(Path(image_path).glob('*/*/*.jpg'))\n",
    "    random_paths = random.sample(image_paths, k=n)\n",
    "    \n",
    "    fig, axes = plt.subplots(1, n, figsize=(15, 5))\n",
    "    for ax, path in zip(axes, random_paths):\n",
    "        img = Image.open(path)\n",
    "        ax.imshow(img)\n",
    "        ax.set_title(f'Class: {path.parent.stem}')\n",
    "        ax.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display Random Sample\n",
    "\n",
    "Now let's use our function to visualize 3 random images from across all classes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_random_images(image_path, n=3, seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observations from Multiple Images\n",
    "\n",
    "From viewing multiple images, we can observe:\n",
    "\n",
    "**Visual Diversity:**\n",
    "- Each food category has distinct visual characteristics\n",
    "- Images vary in terms of angle, zoom level, and presentation\n",
    "- Different lighting conditions and backgrounds\n",
    "\n",
    "**Classification Clues:**\n",
    "- **Pizza**: Circular shape, cheese texture, toppings visible\n",
    "- **Steak**: Brown/charred appearance, meat texture, often with grill marks\n",
    "- **Sushi**: Rice visible, distinct rolls or nigiri shapes, often on plates\n",
    "\n",
    "**Important Notes:**\n",
    "- Some images might be more challenging than others (e.g., close-ups vs. full shots)\n",
    "- Real-world variability means our model needs to learn robust features\n",
    "- This diversity is actually **good** - it helps our model generalize better!\n",
    "\n",
    "ðŸ’¡ **Tip**: If you notice any patterns or potential issues in the data, this is the time to address them before training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Training set:')\n",
    "for d in train_dir.iterdir():\n",
    "    if d.is_dir():\n",
    "        count = len(list(d.glob('*.jpg')))\n",
    "        print(f'  {d.name}: {count} images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Test set:')\n",
    "for d in test_dir.iterdir():\n",
    "    if d.is_dir():\n",
    "        count = len(list(d.glob('*.jpg')))\n",
    "        print(f'  {d.name}: {count} images')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "- Data is organized in ImageFolder format\n",
    "- Variable image sizes, RGB format\n",
    "- Next: Lab 2 - Transform and load with DataLoaders"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
