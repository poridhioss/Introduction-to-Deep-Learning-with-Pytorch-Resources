{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 2: ImageFolder & DataLoaders\n",
    "\n",
    "In this lab, we will learn how to transform images and load them efficiently using PyTorch.\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this lab, you will be able to:\n",
    "- Create image transformation pipelines using `transforms.Compose`\n",
    "- Understand what each transform does (Resize, Flip, ToTensor)\n",
    "- Load data using `ImageFolder` dataset\n",
    "- Create efficient DataLoaders for batched training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Required Libraries\n",
    "\n",
    "We'll import essential PyTorch libraries for data loading and transformations:\n",
    "- `torch` - Core PyTorch library\n",
    "- `DataLoader` - For creating batched, iterable datasets\n",
    "- `datasets` - Pre-built dataset classes (like ImageFolder)\n",
    "- `transforms` - Image transformation utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f'Using device: {device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working with Vision Data\n",
    "\n",
    "Since we're working with a vision problem, we'll use:\n",
    "- **`torchvision.datasets`** - Contains data loading functions for images\n",
    "- **`torchvision.transforms`** - Provides tools for preprocessing and augmenting image data\n",
    "\n",
    "These modules are part of the `torchvision` library, PyTorch's computer vision toolkit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup Data Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import zipfile\n",
    "\n",
    "data_path = Path('data/')\n",
    "image_path = data_path / 'pizza_steak_sushi'\n",
    "\n",
    "if image_path.is_dir():\n",
    "    print(f'{image_path} directory exists.')\n",
    "else:\n",
    "    print(f'Creating {image_path} directory...')\n",
    "    image_path.mkdir(parents=True, exist_ok=True)\n",
    "    with open(data_path / 'pizza_steak_sushi.zip', 'wb') as f:\n",
    "        request = requests.get('https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi.zip')\n",
    "        print('Downloading data...')\n",
    "        f.write(request.content)\n",
    "    with zipfile.ZipFile(data_path / 'pizza_steak_sushi.zip', 'r') as zip_ref:\n",
    "        print('Unzipping data...')\n",
    "        zip_ref.extractall(image_path)\n",
    "    print('Done!')\n",
    "\n",
    "train_dir = image_path / 'train'\n",
    "test_dir = image_path / 'test'\n",
    "\n",
    "print(f'Train dir: {train_dir}')\n",
    "print(f'Test dir: {test_dir}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Transforming Data\n",
    "\n",
    "Now what if we wanted to load our image data into PyTorch?\n",
    "\n",
    "### Requirements for Using Images in PyTorch\n",
    "\n",
    "Before we can use our image data with PyTorch, we need to:\n",
    "\n",
    "1. **Convert to tensors** - Turn images into numerical representations\n",
    "2. **Create a Dataset** - Use `torch.utils.data.Dataset`\n",
    "3. **Create a DataLoader** - Use `torch.utils.data.DataLoader` for batching\n",
    "\n",
    "### Transforming Data with torchvision.transforms\n",
    "\n",
    "We've got folders of images, but before we can use them with PyTorch, we need to convert them into tensors.\n",
    "\n",
    "One of the ways we can do this is by using the **`torchvision.transforms`** module.\n",
    "\n",
    "`torchvision.transforms` contains many pre-built methods for:\n",
    "- Formatting images\n",
    "- Converting them into tensors\n",
    "- Data augmentation (artificially increasing dataset variety)\n",
    "\n",
    "### Why Transform Images?\n",
    "\n",
    "Raw images can't be directly fed to neural networks. We need a series of transform steps:\n",
    "\n",
    "1. **Resize** - Make all images the same size (neural networks expect fixed input dimensions)\n",
    "2. **Augment** - Artificially increase dataset variety (helps prevent overfitting)\n",
    "3. **ToTensor** - Convert PIL Image to PyTorch tensor (normalize pixel values from 0-255 to 0-1)\n",
    "\n",
    "Let's create a transformation pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transform = transforms.Compose([\n",
    "    transforms.Resize(size=(64, 64)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "print('Transform pipeline created!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform Pipeline\n",
    "\n",
    "`transforms.Compose()` chains multiple transforms together:\n",
    "\n",
    "| Transform | What it Does |\n",
    "|-----------|--------------|\n",
    "| `Resize((64, 64))` | Resizes image to 64x64 pixels |\n",
    "| `RandomHorizontalFlip(p=0.5)` | 50% chance to flip image horizontally |\n",
    "| `ToTensor()` | Converts PIL Image → Tensor, scales values to [0, 1] |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Transform Effect\n",
    "\n",
    "Let's see how transforms modify our images. Notice:\n",
    "- **Original**: Variable sizes, PIL Image format\n",
    "- **Transformed**: Fixed 64x64 size, PyTorch tensor format [C, H, W]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import random\n",
    "\n",
    "def plot_transformed_images(image_paths, transform, n=3, seed=42):\n",
    "    random.seed(seed)\n",
    "    random_image_paths = random.sample(image_paths, k=n)\n",
    "    for image_path in random_image_paths:\n",
    "        with Image.open(image_path) as f:\n",
    "            fig, ax = plt.subplots(1, 2)\n",
    "            ax[0].imshow(f)\n",
    "            ax[0].set_title(f\"Original \\nSize: {f.size}\")\n",
    "            ax[0].axis(\"off\")\n",
    "            \n",
    "            transformed_image = transform(f).permute(1, 2, 0)\n",
    "            ax[1].imshow(transformed_image)\n",
    "            ax[1].set_title(f\"Transformed \\nSize: {transformed_image.shape}\")\n",
    "            ax[1].axis(\"off\")\n",
    "            \n",
    "            fig.suptitle(f\"Class: {image_path.parent.stem}\", fontsize=16)\n",
    "            plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding Tensor Dimensions\n",
    "\n",
    "**Important dimension ordering:**\n",
    "- **PyTorch format**: `[C, H, W]` (Channels, Height, Width)\n",
    "- **Matplotlib format**: `[H, W, C]` (Height, Width, Channels)\n",
    "\n",
    "We use `.permute(1, 2, 0)` to rearrange tensor dimensions for visualization:\n",
    "```python\n",
    "# PyTorch: [3, 64, 64] → Matplotlib: [64, 64, 3]\n",
    "tensor.permute(1, 2, 0)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path_list = list(image_path.glob(\"*/*/*.jpg\"))\n",
    "print(f\"Found {len(image_path_list)} images\")\n",
    "\n",
    "plot_transformed_images(image_path_list, data_transform, n=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding Transforms\n",
    "\n",
    "Nice! We've now got a way to convert our images to tensors using `torchvision.transforms`.\n",
    "\n",
    "We can also manipulate their size and orientation if needed (some models prefer images of different sizes and shapes).\n",
    "\n",
    "### Image Size Trade-offs\n",
    "\n",
    "**Image size matters:**\n",
    "- **Larger images** = More information for the model to learn from\n",
    "- **Smaller images** = Faster computation but less detail\n",
    "\n",
    "**Example:**\n",
    "- An image of size `[256, 256, 3]` will have **16x more pixels** than `[64, 64, 3]`\n",
    "- Calculation: `(256×256×3) / (64×64×3) = 16`\n",
    "\n",
    "**The trade-off:**\n",
    "- ✅ More pixels = More information\n",
    "- ⚠️ More pixels = More computations (slower training)\n",
    "\n",
    "**Practical tip:** Start with smaller images (64x64) to prototype quickly, then scale up if needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load Data with ImageFolder\n",
    "\n",
    "Alright, time to turn our image data into a `Dataset` capable of being used with PyTorch.\n",
    "\n",
    "### What is ImageFolder?\n",
    "\n",
    "Since our data is in standard image classification format, we can use the class **`torchvision.datasets.ImageFolder`**.\n",
    "\n",
    "`ImageFolder` is PyTorch's built-in dataset class for image classification. It:\n",
    "- Automatically reads images from folder structure\n",
    "- Assigns labels based on folder names\n",
    "- Applies transforms to each image\n",
    "- Returns `(image_tensor, label)` pairs\n",
    "\n",
    "### How to Use ImageFolder\n",
    "\n",
    "We pass it:\n",
    "1. **`root`** - File path of the target image directory\n",
    "2. **`transform`** - Series of transforms to perform on images\n",
    "\n",
    "Let's test it out on our `train_dir` and `test_dir`, passing in `transform=data_transform` to turn our images into tensors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = datasets.ImageFolder(root=train_dir, transform=data_transform)\n",
    "test_data = datasets.ImageFolder(root=test_dir, transform=data_transform)\n",
    "\n",
    "print(f'Train data: {train_data}')\n",
    "print(f'Test data: {test_data}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Created Successfully!\n",
    "\n",
    "Beautiful! It looks like PyTorch has registered our `Dataset`s.\n",
    "\n",
    "Let's inspect them by checking:\n",
    "- `classes` - List of class names\n",
    "- `class_to_idx` - Dictionary mapping class names to indices\n",
    "- Dataset lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = train_data.classes\n",
    "class_dict = train_data.class_to_idx\n",
    "\n",
    "print(f'Class names: {class_names}')\n",
    "print(f'Class to idx: {class_dict}')\n",
    "print(f'Number of training images: {len(train_data)}')\n",
    "print(f'Number of test images: {len(test_data)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "img, label = train_data[0]\n",
    "\n",
    "print(f\"Image tensor:\\n{img}\")\n",
    "print(f\"Image shape: {img.shape}\")\n",
    "print(f\"Image datatype: {img.dtype}\")\n",
    "print(f\"Image label: {label}\")\n",
    "print(f\"Label datatype: {type(label)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding the Output\n",
    "\n",
    "Our images are now in the form of a **tensor** with:\n",
    "- **Shape**: `[3, 64, 64]` → [Channels, Height, Width]\n",
    "- **Data type**: `torch.float32` (normalized values between 0 and 1)\n",
    "\n",
    "The labels are **integers** relating to a specific class:\n",
    "- Referenced by the `class_to_idx` attribute\n",
    "- `0` = pizza, `1` = steak, `2` = sushi\n",
    "\n",
    "How about we plot a single image tensor using matplotlib?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot a Sample Image\n",
    "\n",
    "**Important**: PyTorch tensors have shape `[C, H, W]` (Channels, Height, Width), but matplotlib expects `[H, W, C]`. We use `.permute(1, 2, 0)` to rearrange dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Permute for matplotlib: [C, H, W] -> [H, W, C]\n",
    "img_permute = img.permute(1, 2, 0)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.imshow(img_permute)\n",
    "plt.title(f'Class: {class_names[label]}')\n",
    "plt.axis(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Quality vs. Resolution\n",
    "\n",
    "Notice the image is now **more pixelated** (less quality).\n",
    "\n",
    "**Why?**\n",
    "- Original size: `512×512` pixels\n",
    "- Resized to: `64×64` pixels\n",
    "- Information loss: ~98.4% reduction in pixels!\n",
    "\n",
    "**Important insight:**\n",
    "> If you think the image is harder to recognize, chances are a model will find it harder to understand too.\n",
    "\n",
    "**Balance to consider:**\n",
    "- Higher resolution = Better quality = Slower training\n",
    "- Lower resolution = Faster training = Potentially lower accuracy\n",
    "\n",
    "For our food classification task, 64×64 is a good starting point!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Create DataLoaders\n",
    "\n",
    "We've got our images as PyTorch `Dataset`s, but now let's turn them into `DataLoader`s.\n",
    "\n",
    "### Why DataLoaders?\n",
    "\n",
    "Training on one image at a time is **inefficient**. **DataLoaders** provide:\n",
    "\n",
    "1. **Batching** - Group multiple images together (e.g., 32 images per batch)\n",
    "   - GPUs excel at parallel computation on batches\n",
    "   - Gradient updates are more stable with batch statistics\n",
    "\n",
    "2. **Shuffling** - Randomize order each epoch\n",
    "   - Prevents model from memorizing the order\n",
    "   - Improves generalization\n",
    "\n",
    "3. **Parallel Loading** - Use multiple CPU workers to load data faster\n",
    "   - Loads next batch while GPU processes current batch\n",
    "   - Reduces training bottlenecks\n",
    "\n",
    "### Creating DataLoaders\n",
    "\n",
    "We'll use `torch.utils.data.DataLoader` to turn our `Dataset`s into `DataLoader`s.\n",
    "\n",
    "This makes them **iterable**, so a model can go through and learn the relationships between samples and targets (features and labels).\n",
    "\n",
    "We'll use:\n",
    "- `batch_size=16` - Process 16 images at once\n",
    "- `num_workers=0` - Use main process for data loading (set to 1+ for parallel loading)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding num_workers\n",
    "\n",
    "**What's `num_workers`?**\n",
    "\n",
    "It defines how many **subprocesses** will be created to load your data.\n",
    "\n",
    "Think of it like this:\n",
    "- **`num_workers=0`**: Main process loads data (simplest, but slower)\n",
    "- **`num_workers=1`**: One subprocess loads data in parallel\n",
    "- **`num_workers=4`**: Four subprocesses load data simultaneously\n",
    "\n",
    "**Performance tip:**\n",
    "The higher `num_workers` is set, the more compute power PyTorch uses to load data.\n",
    "\n",
    "**Best practice:**\n",
    "Set it to the total number of CPUs on your machine using:\n",
    "```python\n",
    "import os\n",
    "num_workers = os.cpu_count()\n",
    "```\n",
    "\n",
    "This ensures the DataLoader recruits as many cores as possible to load data efficiently.\n",
    "\n",
    "**For this tutorial:** We use `num_workers=0` for simplicity (cross-platform compatibility)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    dataset=train_data,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=2\n",
    ")\n",
    "\n",
    "test_dataloader = DataLoader(\n",
    "    dataset=test_data,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=2\n",
    ")\n",
    "\n",
    "print(f'Train dataloader: {train_dataloader}')\n",
    "print(f'Test dataloader: {test_dataloader}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataLoaders Created Successfully!\n",
    "\n",
    "Wonderful! Now our data is **iterable**.\n",
    "\n",
    "Let's try it out and check the shapes of a batch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "img, label = next(iter(train_dataloader))\n",
    "\n",
    "# Batch size will now be 1, try changing the batch_size parameter above and see what happens\n",
    "print(f\"Image shape: {img.shape} -> [batch_size, color_channels, height, width]\")\n",
    "print(f\"Label shape: {label.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could now use these DataLoader's with a training and testing loop to train a model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize a Batch\n",
    "\n",
    "A batch is a group of images processed together. This is more efficient because:\n",
    "- GPUs excel at parallel computation\n",
    "- Gradient updates are more stable with batch statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 4, figsize=(12, 6))\n",
    "for i, ax in enumerate(axes.flatten()):\n",
    "    if i < len(img_batch):\n",
    "        ax.imshow(img_batch[i].permute(1, 2, 0))\n",
    "        ax.set_title(f'{class_names[label_batch[i]]}')\n",
    "        ax.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "| Concept | Shape/Format | Description |\n",
    "|---------|--------------|-------------|\n",
    "| **PIL Image** | (H, W, C) | Original image format |\n",
    "| **Image Tensor** | [C, H, W] | Single image: [3, 64, 64] |\n",
    "| **Batch Tensor** | [N, C, H, W] | Batch of N images: [32, 3, 64, 64] |\n",
    "\n",
    "### Transform Summary\n",
    "\n",
    "```\n",
    "PIL Image (variable size) \n",
    "    → Resize (64x64) \n",
    "    → RandomFlip (augmentation) \n",
    "    → ToTensor [3, 64, 64] (values 0-1)\n",
    "```\n",
    "\n",
    "### What's Next?\n",
    "\n",
    "In **Lab 3**, we'll build a **custom Dataset class** from scratch to understand what happens under the hood!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
