{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 03: Model Architecture Comparison\n",
    "\n",
    "In this notebook, we'll systematically compare different model architectures (EfficientNet-B0 vs B2) to understand the **performance-efficiency trade-off** and select the best model for different deployment scenarios.\n",
    "\n",
    "## Why This Lab Matters\n",
    "\n",
    "Choosing the right model architecture is crucial:\n",
    "- **Mobile apps** need small, fast models\n",
    "- **Cloud services** can use larger, more accurate models\n",
    "- **Edge devices** have strict resource constraints\n",
    "\n",
    "**The key question:** *\"Is the extra accuracy worth the computational cost?\"*\n",
    "\n",
    "## High-Level Workflow\n",
    "\n",
    "![Model Comparison Workflow](https://raw.githubusercontent.com/poridhiEng/lab-asset/refs/heads/main/tensorcode/Deep-learning-with-pytorch/Experiment-Tracking/Tensorboard/lab_03/images/image1.svg)\n",
    "\n",
    "### Workflow Phases\n",
    "\n",
    "| Phase | Focus | What Happens |\n",
    "|-------|-------|--------------|\n",
    "| **Phase 1: Setup** | Prepare environment and data | Install packages, download dataset, create DataLoaders |\n",
    "| **Phase 2: Experiments** | Train and track models | Run 4 experiments (B0/B2 × 5/10 epochs), log to TensorBoard |\n",
    "| **Phase 3: Analysis** | Compare and decide | Visualize results, analyze trade-offs, create decision framework |\n",
    "\n",
    "## Our Experiment Design\n",
    "\n",
    "| Experiment | Model | Epochs | Purpose |\n",
    "|------------|-------|--------|---------|\n",
    "| 1 | EfficientNet-B0 | 5 | Fastest baseline |\n",
    "| 2 | EfficientNet-B0 | 10 | Can longer training help? |\n",
    "| 3 | EfficientNet-B2 | 5 | Larger model, quick training |\n",
    "| 4 | EfficientNet-B2 | 10 | Maximum performance |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Setup and Imports\n",
    "\n",
    "**Phase 1 → Setup**\n",
    "\n",
    "Let's begin by installing the required packages and importing libraries. This prepares our environment for running model comparison experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch torchvision --index-url https://download.pytorch.org/whl/cpu\n",
    "!pip install tensorboard matplotlib pandas seaborn tqdm requests -q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1.1: Import Libraries\n",
    "\n",
    "Import PyTorch, torchvision, and other utilities for model training and visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "from typing import Dict, List, Tuple\n",
    "from pathlib import Path\n",
    "import requests\n",
    "import zipfile\n",
    "from datetime import datetime\n",
    "import os\n",
    "import time\n",
    "\n",
    "# Set style for better plots\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"Torchvision version: {torchvision.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1.2: Setup Device and Seeds\n",
    "\n",
    "Configure the device (CPU/GPU) and set random seeds for reproducible experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device setup\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Set seed for reproducibility\n",
    "def set_seed(seed: int = 42):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "set_seed(42)\n",
    "print(\"Seeds set for reproducibility\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Part 2: Understanding the Models\n\nBefore we run experiments, let's understand what we're comparing.\n\n### Model Architecture Comparison\n\n| Aspect | EfficientNet-B0 | EfficientNet-B2 | Difference |\n|--------|-----------------|-----------------|------------|\n| **Parameters** | 5.3M | 9.2M | 1.7x larger |\n| **FLOPs** | 0.39B | 1.0B | 2.6x more compute |\n| **Input Size** | 224×224 | 260×260 | 1.3x larger |\n| **Accuracy (ImageNet)** | 77.1% | 80.1% | +3% |\n| **Speed** | Fast | Moderate | ~2x slower |\n| **Memory** | ~20MB | ~35MB | 1.8x more |\n\n### When to Use Each Model\n\n**EfficientNet-B0** (Small & Fast): Mobile apps, edge devices, real-time applications\n\n**EfficientNet-B2** (Large & Accurate): Cloud deployment, batch processing, research\n\n**The trade-off:** B2 is almost 2x larger and slower, but only 3% more accurate on ImageNet. Is this worth it for your use case? Let's find out!\n\n## Part 3: Download and Prepare Data\n\n**Phase 1 → Setup**\n\nWe'll use the same food classification dataset (pizza, steak, sushi) for fair comparison across all models."
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3.1: Download Dataset\n",
    "\n",
    "Download the pizza/steak/sushi dataset. This dataset has 225 training images and 75 test images across 3 classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def download_dataset() -> Path:\n    \"\"\"Download the pizza_steak_sushi dataset.\"\"\"\n    data_path = Path(\"data/\")\n    image_path = data_path / \"pizza_steak_sushi\"\n    \n    if image_path.is_dir():\n        print(f\"Dataset already exists at {image_path}\")\n        return image_path\n    \n    # Download and extract\n    print(f\"Downloading dataset...\")\n    image_path.mkdir(parents=True, exist_ok=True)\n    \n    zip_path = data_path / \"pizza_steak_sushi.zip\"\n    url = \"https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi.zip\"\n    \n    with open(zip_path, \"wb\") as f:\n        response = requests.get(url)\n        f.write(response.content)\n    \n    with zipfile.ZipFile(zip_path, \"r\") as zip_ref:\n        print(\"Extracting...\")\n        zip_ref.extractall(image_path)\n    \n    os.remove(zip_path)\n    print(f\"Dataset ready!\")\n    \n    return image_path\n\n# Download dataset\ndata_path = download_dataset()\n\n# Setup paths\ntrain_dir = data_path / \"train\"\ntest_dir = data_path / \"test\"\n\n# Count images\nfor split in [train_dir, test_dir]:\n    total = sum(len(list(class_dir.glob(\"*.jpg\"))) \n                for class_dir in split.iterdir() if class_dir.is_dir())\n    print(f\"{split.name}: {total} images\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Part 4: Create DataLoaders and Models\n\n**Phase 1 → Setup**\n\nDifferent models require different input sizes. B0 uses 224×224 images, while B2 uses 260×260 images for better accuracy.\n\n### Step 4.1: Get Model-Specific Transforms"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get transforms for each model\n",
    "transforms_b0 = torchvision.models.EfficientNet_B0_Weights.DEFAULT.transforms()\n",
    "transforms_b2 = torchvision.models.EfficientNet_B2_Weights.DEFAULT.transforms()\n",
    "\n",
    "print(\"EfficientNet-B0 transforms:\")\n",
    "print(transforms_b0)\n",
    "print(\"\\nEfficientNet-B2 transforms:\")\n",
    "print(transforms_b2)\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "def create_dataloaders(transform):\n",
    "    \"\"\"Create DataLoaders with given transform.\"\"\"\n",
    "    train_dataset = datasets.ImageFolder(train_dir, transform=transform)\n",
    "    test_dataset = datasets.ImageFolder(test_dir, transform=transform)\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    \n",
    "    return train_loader, test_loader, train_dataset.classes\n",
    "\n",
    "# Create DataLoaders for each model\n",
    "train_loader_b0, test_loader_b0, class_names = create_dataloaders(transforms_b0)\n",
    "train_loader_b2, test_loader_b2, _ = create_dataloaders(transforms_b2)\n",
    "\n",
    "print(f\"\\nClasses: {class_names}\")\n",
    "print(f\"Train batches: {len(train_loader_b0)}\")\n",
    "print(f\"Test batches: {len(test_loader_b0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4.2: Create Model Functions\n",
    "\n",
    "We'll use transfer learning: freeze the pretrained base layers and only train the classifier head. This speeds up training significantly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_effnetb0(num_classes: int = 3) -> nn.Module:\n",
    "    \"\"\"Create EfficientNet-B0 with frozen base layers.\"\"\"\n",
    "    weights = torchvision.models.EfficientNet_B0_Weights.DEFAULT\n",
    "    model = torchvision.models.efficientnet_b0(weights=weights)\n",
    "    \n",
    "    # Freeze base layers\n",
    "    for param in model.features.parameters():\n",
    "        param.requires_grad = False\n",
    "    \n",
    "    # Replace classifier\n",
    "    model.classifier = nn.Sequential(\n",
    "        nn.Dropout(p=0.2, inplace=True),\n",
    "        nn.Linear(in_features=1280, out_features=num_classes)\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "def create_effnetb2(num_classes: int = 3) -> nn.Module:\n",
    "    \"\"\"Create EfficientNet-B2 with frozen base layers.\"\"\"\n",
    "    weights = torchvision.models.EfficientNet_B2_Weights.DEFAULT\n",
    "    model = torchvision.models.efficientnet_b2(weights=weights)\n",
    "    \n",
    "    # Freeze base layers\n",
    "    for param in model.features.parameters():\n",
    "        param.requires_grad = False\n",
    "    \n",
    "    # Replace classifier\n",
    "    model.classifier = nn.Sequential(\n",
    "        nn.Dropout(p=0.3, inplace=True),\n",
    "        nn.Linear(in_features=1408, out_features=num_classes)\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Compare model sizes\n",
    "print(\"MODEL ARCHITECTURE COMPARISON\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "model_b0 = create_effnetb0(len(class_names))\n",
    "model_b2 = create_effnetb2(len(class_names))\n",
    "\n",
    "for name, model in [(\"EfficientNet-B0\", model_b0), (\"EfficientNet-B2\", model_b2)]:\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    model_size_mb = total_params * 4 / 1024 / 1024  # Assuming float32\n",
    "    \n",
    "    print(f\"\\n{name}:\")\n",
    "    print(f\"  Total parameters: {total_params:,}\")\n",
    "    print(f\"  Trainable parameters: {trainable_params:,}\")\n",
    "    print(f\"  Estimated size: {model_size_mb:.1f} MB\")\n",
    "\n",
    "# Clean up\n",
    "del model_b0, model_b2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Part 5: Training Functions\n\n**Phase 2 → Experiments**\n\nCreate reusable training and evaluation functions that track time per epoch. This helps us compare efficiency."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(model: nn.Module, dataloader: DataLoader, \n",
    "               loss_fn: nn.Module, optimizer: torch.optim.Optimizer,\n",
    "               device: str) -> Tuple[float, float, float]:\n",
    "    \"\"\"Train for one epoch and measure time.\"\"\"\n",
    "    model.train()\n",
    "    train_loss, correct = 0, 0\n",
    "    start_time = time.time()\n",
    "    \n",
    "    for X, y in dataloader:\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        \n",
    "        y_pred = model(X)\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "        correct += (y_pred.argmax(1) == y).sum().item()\n",
    "    \n",
    "    epoch_time = time.time() - start_time\n",
    "    avg_loss = train_loss / len(dataloader)\n",
    "    accuracy = 100 * correct / len(dataloader.dataset)\n",
    "    \n",
    "    return avg_loss, accuracy, epoch_time\n",
    "\n",
    "def test_step(model: nn.Module, dataloader: DataLoader,\n",
    "              loss_fn: nn.Module, device: str) -> Tuple[float, float]:\n",
    "    \"\"\"Evaluate the model.\"\"\"\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    \n",
    "    with torch.inference_mode():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            \n",
    "            y_pred = model(X)\n",
    "            test_loss += loss_fn(y_pred, y).item()\n",
    "            correct += (y_pred.argmax(1) == y).sum().item()\n",
    "    \n",
    "    avg_loss = test_loss / len(dataloader)\n",
    "    accuracy = 100 * correct / len(dataloader.dataset)\n",
    "    \n",
    "    return avg_loss, accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Part 6: Run Experiments\n\n**Phase 2 → Experiments**\n\nNow we'll run all 4 experiments systematically. Each experiment trains a model and logs metrics to TensorBoard for later comparison.\n\n### Experiment 1: EfficientNet-B0 (5 epochs)\n\n**Baseline:** Start with the smaller, faster model trained for 5 epochs. This is our speed benchmark."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Setup\nset_seed(42)\nmodel_b0_5ep = create_effnetb0(len(class_names)).to(device)\noptimizer = torch.optim.Adam(model_b0_5ep.parameters(), lr=0.001)\nloss_fn = nn.CrossEntropyLoss()\n\n# TensorBoard writer\nwriter_b0_5ep = SummaryWriter(\"runs/model_comparison/effnetb0_5epochs\")\n\nprint(\"EXPERIMENT 1: EfficientNet-B0 (5 epochs)\")\nprint(\"=\"*50)\n\n# Training\nresults_b0_5ep = {\"train_loss\": [], \"train_acc\": [], \"test_loss\": [], \"test_acc\": [], \"epoch_time\": []}\n\nfor epoch in range(5):\n    train_loss, train_acc, epoch_time = train_step(\n        model_b0_5ep, train_loader_b0, loss_fn, optimizer, device\n    )\n    test_loss, test_acc = test_step(\n        model_b0_5ep, test_loader_b0, loss_fn, device\n    )\n    \n    # Store results\n    results_b0_5ep[\"train_loss\"].append(train_loss)\n    results_b0_5ep[\"train_acc\"].append(train_acc)\n    results_b0_5ep[\"test_loss\"].append(test_loss)\n    results_b0_5ep[\"test_acc\"].append(test_acc)\n    results_b0_5ep[\"epoch_time\"].append(epoch_time)\n    \n    # Log to TensorBoard\n    writer_b0_5ep.add_scalars(\"Loss\", {\"train\": train_loss, \"test\": test_loss}, epoch)\n    writer_b0_5ep.add_scalars(\"Accuracy\", {\"train\": train_acc, \"test\": test_acc}, epoch)\n    \n    print(f\"Epoch {epoch+1}: Test Acc: {test_acc:.2f}% | Time: {epoch_time:.1f}s\")\n\nwriter_b0_5ep.close()\n\ntotal_time_b0_5ep = sum(results_b0_5ep[\"epoch_time\"])\nprint(f\"\\nComplete! Final accuracy: {results_b0_5ep['test_acc'][-1]:.2f}%\")\nprint(f\"Total training time: {total_time_b0_5ep:.1f}s\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ""
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 2: EfficientNet-B0 (10 epochs)\n",
    "\n",
    "**Question:** Does training longer help the smaller model? Can B0 close the accuracy gap with more epochs?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Setup\nset_seed(42)\nmodel_b0_10ep = create_effnetb0(len(class_names)).to(device)\noptimizer = torch.optim.Adam(model_b0_10ep.parameters(), lr=0.001)\n\n# TensorBoard writer\nwriter_b0_10ep = SummaryWriter(\"runs/model_comparison/effnetb0_10epochs\")\n\nprint(\"EXPERIMENT 2: EfficientNet-B0 (10 epochs)\")\nprint(\"=\"*50)\n\n# Training\nresults_b0_10ep = {\"train_loss\": [], \"train_acc\": [], \"test_loss\": [], \"test_acc\": [], \"epoch_time\": []}\n\nfor epoch in range(10):\n    train_loss, train_acc, epoch_time = train_step(\n        model_b0_10ep, train_loader_b0, loss_fn, optimizer, device\n    )\n    test_loss, test_acc = test_step(\n        model_b0_10ep, test_loader_b0, loss_fn, device\n    )\n    \n    # Store results\n    results_b0_10ep[\"train_loss\"].append(train_loss)\n    results_b0_10ep[\"train_acc\"].append(train_acc)\n    results_b0_10ep[\"test_loss\"].append(test_loss)\n    results_b0_10ep[\"test_acc\"].append(test_acc)\n    results_b0_10ep[\"epoch_time\"].append(epoch_time)\n    \n    # Log to TensorBoard\n    writer_b0_10ep.add_scalars(\"Loss\", {\"train\": train_loss, \"test\": test_loss}, epoch)\n    writer_b0_10ep.add_scalars(\"Accuracy\", {\"train\": train_acc, \"test\": test_acc}, epoch)\n    \n    print(f\"Epoch {epoch+1}: Test Acc: {test_acc:.2f}% | Time: {epoch_time:.1f}s\")\n\nwriter_b0_10ep.close()\n\ntotal_time_b0_10ep = sum(results_b0_10ep[\"epoch_time\"])\nprint(f\"\\nComplete! Final accuracy: {results_b0_10ep['test_acc'][-1]:.2f}%\")\nprint(f\"Total training time: {total_time_b0_10ep:.1f}s\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ""
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 3: EfficientNet-B2 (5 epochs)\n",
    "\n",
    "**Larger Model:** Now let's try the bigger model with the same 5 epochs. Will it outperform B0 despite having less training time per image?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Setup\nset_seed(42)\nmodel_b2_5ep = create_effnetb2(len(class_names)).to(device)\noptimizer = torch.optim.Adam(model_b2_5ep.parameters(), lr=0.001)\n\n# TensorBoard writer\nwriter_b2_5ep = SummaryWriter(\"runs/model_comparison/effnetb2_5epochs\")\n\nprint(\"EXPERIMENT 3: EfficientNet-B2 (5 epochs)\")\nprint(\"=\"*50)\n\n# Training\nresults_b2_5ep = {\"train_loss\": [], \"train_acc\": [], \"test_loss\": [], \"test_acc\": [], \"epoch_time\": []}\n\nfor epoch in range(5):\n    train_loss, train_acc, epoch_time = train_step(\n        model_b2_5ep, train_loader_b2, loss_fn, optimizer, device\n    )\n    test_loss, test_acc = test_step(\n        model_b2_5ep, test_loader_b2, loss_fn, device\n    )\n    \n    # Store results\n    results_b2_5ep[\"train_loss\"].append(train_loss)\n    results_b2_5ep[\"train_acc\"].append(train_acc)\n    results_b2_5ep[\"test_loss\"].append(test_loss)\n    results_b2_5ep[\"test_acc\"].append(test_acc)\n    results_b2_5ep[\"epoch_time\"].append(epoch_time)\n    \n    # Log to TensorBoard\n    writer_b2_5ep.add_scalars(\"Loss\", {\"train\": train_loss, \"test\": test_loss}, epoch)\n    writer_b2_5ep.add_scalars(\"Accuracy\", {\"train\": train_acc, \"test\": test_acc}, epoch)\n    \n    print(f\"Epoch {epoch+1}: Test Acc: {test_acc:.2f}% | Time: {epoch_time:.1f}s\")\n\nwriter_b2_5ep.close()\n\ntotal_time_b2_5ep = sum(results_b2_5ep[\"epoch_time\"])\nprint(f\"\\nComplete! Final accuracy: {results_b2_5ep['test_acc'][-1]:.2f}%\")\nprint(f\"Total training time: {total_time_b2_5ep:.1f}s\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 4: EfficientNet-B2 (10 epochs)\n",
    "\n",
    "**Maximum Performance:** The largest model with the longest training time. This is our accuracy benchmark — how much better can we do with more resources?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Setup\nset_seed(42)\nmodel_b2_10ep = create_effnetb2(len(class_names)).to(device)\noptimizer = torch.optim.Adam(model_b2_10ep.parameters(), lr=0.001)\n\n# TensorBoard writer\nwriter_b2_10ep = SummaryWriter(\"runs/model_comparison/effnetb2_10epochs\")\n\nprint(\"EXPERIMENT 4: EfficientNet-B2 (10 epochs)\")\nprint(\"=\"*50)\n\n# Training\nresults_b2_10ep = {\"train_loss\": [], \"train_acc\": [], \"test_loss\": [], \"test_acc\": [], \"epoch_time\": []}\n\nfor epoch in range(10):\n    train_loss, train_acc, epoch_time = train_step(\n        model_b2_10ep, train_loader_b2, loss_fn, optimizer, device\n    )\n    test_loss, test_acc = test_step(\n        model_b2_10ep, test_loader_b2, loss_fn, device\n    )\n    \n    # Store results\n    results_b2_10ep[\"train_loss\"].append(train_loss)\n    results_b2_10ep[\"train_acc\"].append(train_acc)\n    results_b2_10ep[\"test_loss\"].append(test_loss)\n    results_b2_10ep[\"test_acc\"].append(test_acc)\n    results_b2_10ep[\"epoch_time\"].append(epoch_time)\n    \n    # Log to TensorBoard\n    writer_b2_10ep.add_scalars(\"Loss\", {\"train\": train_loss, \"test\": test_loss}, epoch)\n    writer_b2_10ep.add_scalars(\"Accuracy\", {\"train\": train_acc, \"test\": test_acc}, epoch)\n    \n    print(f\"Epoch {epoch+1}: Test Acc: {test_acc:.2f}% | Time: {epoch_time:.1f}s\")\n\nwriter_b2_10ep.close()\n\ntotal_time_b2_10ep = sum(results_b2_10ep[\"epoch_time\"])\nprint(f\"\\nComplete! Final accuracy: {results_b2_10ep['test_acc'][-1]:.2f}%\")\nprint(f\"Total training time: {total_time_b2_10ep:.1f}s\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ""
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Part 7: View Results in TensorBoard\n\n**Phase 3 → Analysis**\n\nNow let's visualize all 4 experiments together to compare their performance side-by-side."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, subprocess, time\n",
    "\n",
    "ip = requests.get(\"https://ifconfig.me\").text.strip()\n",
    "\n",
    "subprocess.Popen(\n",
    "    [\"tensorboard\", \"--logdir=runs/model_comparison\", \"--port=6006\", \"--host=0.0.0.0\"],\n",
    "    stdout=subprocess.DEVNULL,\n",
    "    stderr=subprocess.DEVNULL\n",
    ")\n",
    "\n",
    "time.sleep(2)\n",
    "print(f\"TensorBoard running at: http://{ip}:6006\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Access TensorBoard in your browser to compare all 4 experiments side-by-side. You can:\n",
    "- Compare accuracy and loss curves across all experiments\n",
    "- Use the smoothing slider to reduce noise\n",
    "- Toggle experiments on/off for detailed comparisons\n",
    "- Analyze which model converges faster\n",
    "\n",
    "### TensorBoard Results\n",
    "\n",
    "<table>\n",
    "<tr>\n",
    "<td><img src=\"https://raw.githubusercontent.com/poridhiEng/lab-asset/refs/heads/main/tensorcode/Deep-learning-with-pytorch/Experiment-Tracking/Tensorboard/lab_03/images/b0-5e.png\" alt=\"B0 5 epochs\" width=\"400\"/></td>\n",
    "<td><img src=\"https://raw.githubusercontent.com/poridhiEng/lab-asset/refs/heads/main/tensorcode/Deep-learning-with-pytorch/Experiment-Tracking/Tensorboard/lab_03/images/b0-10e.png\" alt=\"B0 10 epochs\" width=\"400\"/></td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td align=\"center\"><b>EfficientNet-B0 (5 epochs)</b></td>\n",
    "<td align=\"center\"><b>EfficientNet-B0 (10 epochs)</b></td>\n",
    "</tr>\n",
    "</table>\n",
    "\n",
    "<table>\n",
    "<tr>\n",
    "<td><img src=\"https://raw.githubusercontent.com/poridhiEng/lab-asset/refs/heads/main/tensorcode/Deep-learning-with-pytorch/Experiment-Tracking/Tensorboard/lab_03/images/b2-5e.png\" alt=\"B2 5 epochs\" width=\"400\"/></td>\n",
    "<td><img src=\"https://raw.githubusercontent.com/poridhiEng/lab-asset/refs/heads/main/tensorcode/Deep-learning-with-pytorch/Experiment-Tracking/Tensorboard/lab_03/images/b2-10e.png\" alt=\"B2 10 epochs\" width=\"400\"/></td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td align=\"center\"><b>EfficientNet-B2 (5 epochs)</b></td>\n",
    "<td align=\"center\"><b>EfficientNet-B2 (10 epochs)</b></td>\n",
    "</tr>\n",
    "</table>\n",
    "\n",
    "**Key Observations from TensorBoard:**\n",
    "- **B2 converges faster** than B0 in early epochs\n",
    "- **B0 with 10 epochs** closes the gap significantly (+5% improvement)\n",
    "- **B2 plateaus** after ~7 epochs (diminishing returns)\n",
    "- **Loss curves** show B2 has slightly better convergence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Part 8: Compare Results\n\n**Phase 3 → Analysis**\n\nNow let's create comprehensive comparison visualizations and analyze which model performs best.\n\n### Step 8.1: Results Summary Table"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Create results summary\nexperiments = [\n    {\"Model\": \"B0\", \"Epochs\": 5, \"Final Acc\": results_b0_5ep['test_acc'][-1], \n     \"Best Acc\": max(results_b0_5ep['test_acc']), \"Time (s)\": total_time_b0_5ep,\n     \"Time/Epoch\": total_time_b0_5ep/5},\n    \n    {\"Model\": \"B0\", \"Epochs\": 10, \"Final Acc\": results_b0_10ep['test_acc'][-1], \n     \"Best Acc\": max(results_b0_10ep['test_acc']), \"Time (s)\": total_time_b0_10ep,\n     \"Time/Epoch\": total_time_b0_10ep/10},\n    \n    {\"Model\": \"B2\", \"Epochs\": 5, \"Final Acc\": results_b2_5ep['test_acc'][-1], \n     \"Best Acc\": max(results_b2_5ep['test_acc']), \"Time (s)\": total_time_b2_5ep,\n     \"Time/Epoch\": total_time_b2_5ep/5},\n    \n    {\"Model\": \"B2\", \"Epochs\": 10, \"Final Acc\": results_b2_10ep['test_acc'][-1], \n     \"Best Acc\": max(results_b2_10ep['test_acc']), \"Time (s)\": total_time_b2_10ep,\n     \"Time/Epoch\": total_time_b2_10ep/10},\n]\n\nresults_df = pd.DataFrame(experiments)\nresults_df = results_df.sort_values('Final Acc', ascending=False)\n\nprint(\"EXPERIMENT RESULTS (Sorted by Performance)\")\nprint(\"=\"*70)\nprint(results_df.to_string(index=False, float_format='%.2f'))\n\n# Best overall\nbest = results_df.iloc[0]\nprint(f\"\\nBEST MODEL: {best['Model']} trained for {best['Epochs']} epochs\")\nprint(f\"   Accuracy: {best['Final Acc']:.2f}%\")\nprint(f\"   Training time: {best['Time (s)']:.1f}s\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 8.2: Performance vs Efficiency Visualization\n",
    "\n",
    "Visualize the trade-off: accuracy vs training time. This reveals which models are most efficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create visualization\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Plot 1: Accuracy Comparison\n",
    "x_pos = np.arange(4)\n",
    "labels = ['B0-5ep', 'B0-10ep', 'B2-5ep', 'B2-10ep']\n",
    "accuracies = [\n",
    "    results_b0_5ep['test_acc'][-1],\n",
    "    results_b0_10ep['test_acc'][-1],\n",
    "    results_b2_5ep['test_acc'][-1],\n",
    "    results_b2_10ep['test_acc'][-1]\n",
    "]\n",
    "\n",
    "colors = ['#3498db', '#2980b9', '#e74c3c', '#c0392b']\n",
    "bars1 = axes[0].bar(x_pos, accuracies, color=colors, alpha=0.8)\n",
    "axes[0].set_xlabel('Configuration')\n",
    "axes[0].set_ylabel('Test Accuracy (%)')\n",
    "axes[0].set_title('Model Performance Comparison', fontweight='bold')\n",
    "axes[0].set_xticks(x_pos)\n",
    "axes[0].set_xticklabels(labels)\n",
    "axes[0].grid(True, axis='y', alpha=0.3)\n",
    "\n",
    "# Add value labels on bars\n",
    "for bar, acc in zip(bars1, accuracies):\n",
    "    height = bar.get_height()\n",
    "    axes[0].text(bar.get_x() + bar.get_width()/2., height + 0.5,\n",
    "                f'{acc:.1f}%', ha='center', va='bottom')\n",
    "\n",
    "# Plot 2: Time Comparison\n",
    "times = [\n",
    "    total_time_b0_5ep,\n",
    "    total_time_b0_10ep,\n",
    "    total_time_b2_5ep,\n",
    "    total_time_b2_10ep\n",
    "]\n",
    "\n",
    "bars2 = axes[1].bar(x_pos, times, color=colors, alpha=0.8)\n",
    "axes[1].set_xlabel('Configuration')\n",
    "axes[1].set_ylabel('Training Time (seconds)')\n",
    "axes[1].set_title('Training Time Comparison', fontweight='bold')\n",
    "axes[1].set_xticks(x_pos)\n",
    "axes[1].set_xticklabels(labels)\n",
    "axes[1].grid(True, axis='y', alpha=0.3)\n",
    "\n",
    "# Add value labels\n",
    "for bar, time in zip(bars2, times):\n",
    "    height = bar.get_height()\n",
    "    axes[1].text(bar.get_x() + bar.get_width()/2., height + 1,\n",
    "                f'{time:.0f}s', ha='center', va='bottom')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('model_comparison.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 8.3: Learning Curves Comparison\n",
    "\n",
    "Compare how each model learns over time. Do they converge at the same rate? Does one plateau earlier?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot learning curves\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Prepare data for 10-epoch experiments (for fair comparison)\n",
    "epochs_10 = range(1, 11)\n",
    "epochs_5 = range(1, 6)\n",
    "\n",
    "# Plot 1: Test Accuracy Over Time\n",
    "axes[0].plot(epochs_10, results_b0_10ep['test_acc'], 'o-', label='B0 (10 epochs)', \n",
    "            color='#3498db', linewidth=2, markersize=6)\n",
    "axes[0].plot(epochs_10, results_b2_10ep['test_acc'], 's-', label='B2 (10 epochs)', \n",
    "            color='#e74c3c', linewidth=2, markersize=6)\n",
    "axes[0].plot(epochs_5, results_b0_5ep['test_acc'], 'o--', label='B0 (5 epochs)', \n",
    "            color='#3498db', alpha=0.6, linewidth=2, markersize=6)\n",
    "axes[0].plot(epochs_5, results_b2_5ep['test_acc'], 's--', label='B2 (5 epochs)', \n",
    "            color='#e74c3c', alpha=0.6, linewidth=2, markersize=6)\n",
    "\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Test Accuracy (%)')\n",
    "axes[0].set_title('Learning Curves: Test Accuracy', fontweight='bold')\n",
    "axes[0].legend(loc='lower right')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Test Loss Over Time\n",
    "axes[1].plot(epochs_10, results_b0_10ep['test_loss'], 'o-', label='B0 (10 epochs)', \n",
    "            color='#3498db', linewidth=2, markersize=6)\n",
    "axes[1].plot(epochs_10, results_b2_10ep['test_loss'], 's-', label='B2 (10 epochs)', \n",
    "            color='#e74c3c', linewidth=2, markersize=6)\n",
    "axes[1].plot(epochs_5, results_b0_5ep['test_loss'], 'o--', label='B0 (5 epochs)', \n",
    "            color='#3498db', alpha=0.6, linewidth=2, markersize=6)\n",
    "axes[1].plot(epochs_5, results_b2_5ep['test_loss'], 's--', label='B2 (5 epochs)', \n",
    "            color='#e74c3c', alpha=0.6, linewidth=2, markersize=6)\n",
    "\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('Test Loss')\n",
    "axes[1].set_title('Learning Curves: Test Loss', fontweight='bold')\n",
    "axes[1].legend(loc='upper right')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('learning_curves.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Part 9: Decision Framework\n\n**Phase 3 → Analysis**\n\nBased on our experimental results, let's create a decision framework for choosing the right model for different scenarios."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "print(\"DECISION FRAMEWORK\")\nprint(\"=\"*70)\n\n# Calculate metrics\nb0_5_efficiency = results_b0_5ep['test_acc'][-1] / total_time_b0_5ep\nb0_10_efficiency = results_b0_10ep['test_acc'][-1] / total_time_b0_10ep\nb2_5_efficiency = results_b2_5ep['test_acc'][-1] / total_time_b2_5ep\nb2_10_efficiency = results_b2_10ep['test_acc'][-1] / total_time_b2_10ep\n\nscenarios = [\n    {\n        \"Scenario\": \"Mobile/Edge Deployment\",\n        \"Recommendation\": \"EfficientNet-B0 (5 epochs)\",\n        \"Why\": \"Smallest model, fastest inference\",\n        \"Accuracy\": f\"{results_b0_5ep['test_acc'][-1]:.1f}%\",\n        \"Time\": f\"{total_time_b0_5ep:.0f}s\"\n    },\n    {\n        \"Scenario\": \"Balanced Performance\",\n        \"Recommendation\": \"EfficientNet-B0 (10 epochs)\",\n        \"Why\": \"Good accuracy, still fast\",\n        \"Accuracy\": f\"{results_b0_10ep['test_acc'][-1]:.1f}%\",\n        \"Time\": f\"{total_time_b0_10ep:.0f}s\"\n    },\n    {\n        \"Scenario\": \"Quick Prototyping\",\n        \"Recommendation\": \"EfficientNet-B2 (5 epochs)\",\n        \"Why\": \"Better accuracy, moderate time\",\n        \"Accuracy\": f\"{results_b2_5ep['test_acc'][-1]:.1f}%\",\n        \"Time\": f\"{total_time_b2_5ep:.0f}s\"\n    },\n    {\n        \"Scenario\": \"Maximum Accuracy\",\n        \"Recommendation\": \"EfficientNet-B2 (10 epochs)\",\n        \"Why\": \"Best performance overall\",\n        \"Accuracy\": f\"{results_b2_10ep['test_acc'][-1]:.1f}%\",\n        \"Time\": f\"{total_time_b2_10ep:.0f}s\"\n    }\n]\n\nscenario_df = pd.DataFrame(scenarios)\nprint(scenario_df.to_string(index=False))\n\nprint(\"\\nEFFICIENCY ANALYSIS (Accuracy per second):\")\nprint(f\"  B0 (5 epochs):  {b0_5_efficiency:.3f}\")\nprint(f\"  B0 (10 epochs): {b0_10_efficiency:.3f}\")\nprint(f\"  B2 (5 epochs):  {b2_5_efficiency:.3f}\")\nprint(f\"  B2 (10 epochs): {b2_10_efficiency:.3f}\")\n\nbest_efficiency = max(b0_5_efficiency, b0_10_efficiency, b2_5_efficiency, b2_10_efficiency)\nif b0_5_efficiency == best_efficiency:\n    print(\"\\nMost efficient: B0 with 5 epochs\")\nelif b0_10_efficiency == best_efficiency:\n    print(\"\\nMost efficient: B0 with 10 epochs\")\nelif b2_5_efficiency == best_efficiency:\n    print(\"\\nMost efficient: B2 with 5 epochs\")\nelse:\n    print(\"\\nMost efficient: B2 with 10 epochs\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Part 10: Summary and Key Takeaways\n\nCongratulations! You've completed a systematic model architecture comparison.\n\n### What We Discovered\n\n| Metric | Finding |\n|--------|---------|\n| **Best Accuracy** | B2-10ep: 93% (best epoch) |\n| **Most Efficient** | B0-5ep: 0.47 accuracy/second |\n| **Sweet Spot** | B0-10ep: 89% in ~6 minutes |\n| **Size Difference** | B2 is 1.9x larger (29MB vs 15MB) |\n\n### Practical Insights\n\n1. **B2 is only 2-3% more accurate** despite being 2x larger and slower\n2. **Longer training helps B0 more** (+5%) than B2 (+0%)\n3. **B0 is sufficient** for most applications (84-89% accuracy)\n4. **Efficiency matters** — B0 trains 2.5x faster per epoch\n\n### Deployment Recommendations\n\n| Scenario | Choose | Why |\n|----------|--------|-----|\n| **Mobile/Edge** | B0 (5-10 ep) | Small size, fast inference |\n| **Cloud/Server** | B2 (5-10 ep) | Accuracy is priority |\n| **Prototyping** | B0 (5 ep) | Fastest iteration |\n| **Production** | B0 (10 ep) | Balanced performance |\n\n### Next Steps\n\n1. **Try other models** — ResNet, MobileNet, VisionTransformer\n2. **Optimize further** — Quantization, pruning, distillation\n3. **Test learning rates** — Larger models may need different schedules\n4. **Add augmentation** — May help smaller models close the gap\n5. **Apply to your data** — Results vary by domain\n\n**Key Lesson:** The best model depends on your constraints, not just accuracy!"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}