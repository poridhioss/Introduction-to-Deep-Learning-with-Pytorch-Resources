{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 02: Training & Evaluating a Transfer Learning Model\n",
    "\n",
    "In Lab 01, we set up our transfer learning pipeline: downloaded a pretrained EfficientNet_B0 model, froze the base layers, and modified the classifier. Now it's time to train and see the power of transfer learning!\n",
    "\n",
    "**Our goal**: Train the model on pizza/steak/sushi images and achieve high accuracy with minimal training.\n",
    "\n",
    "![Our Problem](https://raw.githubusercontent.com/poridhiEng/lab-asset/3cf35c4bc9e49c2beebb77f8f30429b9aecfb753/tensorcode/Deep-learning-with-pytorch/Transfer-learning-with-pytorch/Lab_02/images/infra-3.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Dependencies\n",
    "\n",
    "First, let's install the required libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install requests torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu\n",
    "!pip install torchinfo matplotlib tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup from Lab 01\n",
    "\n",
    "Before we start training, we need to recreate everything from Lab 01:\n",
    "- Download the dataset\n",
    "- Create DataLoaders with proper transforms\n",
    "- Load pretrained EfficientNet_B0\n",
    "- Freeze base layers and modify classifier\n",
    "\n",
    "Run this cell to set everything up:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from torchinfo import summary\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import zipfile\n",
    "import requests\n",
    "from pathlib import Path\n",
    "from typing import List, Tuple\n",
    "from PIL import Image\n",
    "import random\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"Torchvision version: {torchvision.__version__}\")\n",
    "\n",
    "# Setup device\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download and setup data\n",
    "data_path = Path(\"data/\")\n",
    "image_path = data_path / \"pizza_steak_sushi\"\n",
    "\n",
    "if image_path.is_dir():\n",
    "    print(f\"{image_path} directory exists.\")\n",
    "else:\n",
    "    print(f\"Downloading data...\")\n",
    "    image_path.mkdir(parents=True, exist_ok=True)\n",
    "    with open(data_path / \"pizza_steak_sushi.zip\", \"wb\") as f:\n",
    "        # Use raw.githubusercontent.com to get the actual file\n",
    "        request = requests.get(\"https://raw.githubusercontent.com/poridhioss/Introduction-to-Deep-Learning-with-Pytorch-Resources/main/Transfer-learning/pizza_steak_sushi.zip\")\n",
    "        f.write(request.content)\n",
    "    # The zip contains train/ and test/ folders directly, so extract to image_path\n",
    "    with zipfile.ZipFile(data_path / \"pizza_steak_sushi.zip\", \"r\") as zip_ref:\n",
    "        zip_ref.extractall(image_path)  # Extract to data/pizza_steak_sushi/\n",
    "    os.remove(data_path / \"pizza_steak_sushi.zip\")\n",
    "    print(\"Done!\")\n",
    "\n",
    "train_dir = image_path / \"train\"\n",
    "test_dir = image_path / \"test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get pretrained weights and transforms\n",
    "weights = torchvision.models.EfficientNet_B0_Weights.DEFAULT\n",
    "auto_transforms = weights.transforms()\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = datasets.ImageFolder(root=train_dir, transform=auto_transforms)\n",
    "test_dataset = datasets.ImageFolder(root=test_dir, transform=auto_transforms)\n",
    "\n",
    "class_names = train_dataset.classes\n",
    "print(f\"Class names: {class_names}\")\n",
    "\n",
    "# Create DataLoaders\n",
    "BATCH_SIZE = 32\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
    "\n",
    "print(f\"Training samples: {len(train_dataset)}\")\n",
    "print(f\"Test samples: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pretrained model\n",
    "model = torchvision.models.efficientnet_b0(weights=weights).to(device)\n",
    "\n",
    "# Freeze base layers\n",
    "for param in model.features.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Modify classifier\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)\n",
    "\n",
    "model.classifier = nn.Sequential(\n",
    "    nn.Dropout(p=0.2, inplace=True),\n",
    "    nn.Linear(in_features=1280, out_features=len(class_names), bias=True)\n",
    ").to(device)\n",
    "\n",
    "print(\"Model setup complete!\")\n",
    "print(f\"Trainable parameters: {sum(p.numel() for p in model.parameters() if p.requires_grad):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Create Loss Function and Optimizer\n",
    "\n",
    "For multiclass classification, we use:\n",
    "- **CrossEntropyLoss**: Standard loss for classification (includes softmax internally)\n",
    "- **Adam optimizer**: Adaptive learning rate optimizer, works well with transfer learning\n",
    "\n",
    "We use `lr=0.001` as a starting learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss function and optimizer\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "print(f\"Loss function: {loss_fn}\")\n",
    "print(f\"Optimizer: {optimizer}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create Training and Testing Step Functions\n",
    "\n",
    "Let's create reusable functions for training and testing. The diagram below shows the training loop process:\n",
    "\n",
    "![Training Loop](https://raw.githubusercontent.com/poridhiEng/lab-asset/3cf35c4bc9e49c2beebb77f8f30429b9aecfb753/tensorcode/Deep-learning-with-pytorch/Transfer-learning-with-pytorch/Lab_02/images/infra-2.svg)\n",
    "\n",
    "For each epoch, we iterate through batches of data and perform these steps: zero the gradients (`optimizer.zero_grad()`), run the forward pass (`model(features)`), compute the loss, run the backward pass (`loss.backward()`), and update weights with the optimizer (`optimizer.step()`). This cycle repeats for every batch until all epochs are complete.\n",
    "\n",
    "### Training Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(model: nn.Module,\n",
    "               dataloader: DataLoader,\n",
    "               loss_fn: nn.Module,\n",
    "               optimizer: torch.optim.Optimizer,\n",
    "               device: torch.device) -> Tuple[float, float]:\n",
    "    \"\"\"Performs a training step.\n",
    "    \n",
    "    Returns:\n",
    "        Tuple of (train_loss, train_accuracy)\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    train_loss, train_acc = 0, 0\n",
    "    \n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        # Send data to device\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        \n",
    "        # 1. Zero gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # 2. Forward pass\n",
    "        y_pred = model(X)\n",
    "        \n",
    "        # 3. Calculate loss\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        train_loss += loss.item()\n",
    "        \n",
    "        # 4. Backward pass\n",
    "        loss.backward()\n",
    "        \n",
    "        # 5. Optimizer step\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Calculate accuracy\n",
    "        y_pred_class = torch.argmax(torch.softmax(y_pred, dim=1), dim=1)\n",
    "        train_acc += (y_pred_class == y).sum().item() / len(y)\n",
    "    \n",
    "    # Average loss and accuracy\n",
    "    train_loss = train_loss / len(dataloader)\n",
    "    train_acc = train_acc / len(dataloader)\n",
    "    \n",
    "    return train_loss, train_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Step\n",
    "\n",
    "Similar to training, but:\n",
    "- Use `model.eval()` mode\n",
    "- Use `torch.inference_mode()` context (no gradient tracking)\n",
    "- No optimizer step (we're just evaluating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_step(model: nn.Module,\n",
    "              dataloader: DataLoader,\n",
    "              loss_fn: nn.Module,\n",
    "              device: torch.device) -> Tuple[float, float]:\n",
    "    \"\"\"Performs a testing step.\n",
    "    \n",
    "    Returns:\n",
    "        Tuple of (test_loss, test_accuracy)\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    test_loss, test_acc = 0, 0\n",
    "    \n",
    "    with torch.inference_mode():\n",
    "        for batch, (X, y) in enumerate(dataloader):\n",
    "            # Send data to device\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            y_pred = model(X)\n",
    "            \n",
    "            # Calculate loss\n",
    "            loss = loss_fn(y_pred, y)\n",
    "            test_loss += loss.item()\n",
    "            \n",
    "            # Calculate accuracy\n",
    "            y_pred_class = torch.argmax(torch.softmax(y_pred, dim=1), dim=1)\n",
    "            test_acc += (y_pred_class == y).sum().item() / len(y)\n",
    "    \n",
    "    # Average loss and accuracy\n",
    "    test_loss = test_loss / len(dataloader)\n",
    "    test_acc = test_acc / len(dataloader)\n",
    "    \n",
    "    return test_loss, test_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train the Model\n",
    "\n",
    "Now let's train our model! We'll train for **5 epochs** and track:\n",
    "- Training loss and accuracy\n",
    "- Test loss and accuracy\n",
    "\n",
    "We'll store results in a dictionary for easy plotting later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from timeit import default_timer as timer\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)\n",
    "\n",
    "# Set number of epochs\n",
    "NUM_EPOCHS = 5\n",
    "\n",
    "# Create results dictionary\n",
    "results = {\n",
    "    \"train_loss\": [],\n",
    "    \"train_acc\": [],\n",
    "    \"test_loss\": [],\n",
    "    \"test_acc\": []\n",
    "}\n",
    "\n",
    "# Start timer\n",
    "start_time = timer()\n",
    "\n",
    "# Training loop\n",
    "for epoch in tqdm(range(NUM_EPOCHS)):\n",
    "    # Training step\n",
    "    train_loss, train_acc = train_step(\n",
    "        model=model,\n",
    "        dataloader=train_dataloader,\n",
    "        loss_fn=loss_fn,\n",
    "        optimizer=optimizer,\n",
    "        device=device\n",
    "    )\n",
    "    \n",
    "    # Testing step\n",
    "    test_loss, test_acc = test_step(\n",
    "        model=model,\n",
    "        dataloader=test_dataloader,\n",
    "        loss_fn=loss_fn,\n",
    "        device=device\n",
    "    )\n",
    "    \n",
    "    # Store results\n",
    "    results[\"train_loss\"].append(train_loss)\n",
    "    results[\"train_acc\"].append(train_acc)\n",
    "    results[\"test_loss\"].append(test_loss)\n",
    "    results[\"test_acc\"].append(test_acc)\n",
    "    \n",
    "    # Print progress\n",
    "    print(\n",
    "        f\"Epoch: {epoch+1} | \"\n",
    "        f\"Train Loss: {train_loss:.4f} | \"\n",
    "        f\"Train Acc: {train_acc:.4f} | \"\n",
    "        f\"Test Loss: {test_loss:.4f} | \"\n",
    "        f\"Test Acc: {test_acc:.4f}\"\n",
    "    )\n",
    "\n",
    "# End timer\n",
    "end_time = timer()\n",
    "print(f\"\\n[INFO] Total training time: {end_time - start_time:.3f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Results\n",
    "\n",
    "Look at those results! In just 5 epochs and a few seconds of training, we achieved **~85%+ test accuracy**.\n",
    "\n",
    "That's the power of transfer learning!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Plot Loss Curves\n",
    "\n",
    "Let's visualize the training progress with loss curves. This helps us understand:\n",
    "- Is the model learning? (loss decreasing)\n",
    "- Is it overfitting? (train loss low, test loss high)\n",
    "- Is it underfitting? (both losses high)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss_curves(results: dict):\n",
    "    \"\"\"Plots training and test loss/accuracy curves.\"\"\"\n",
    "    epochs = range(1, len(results[\"train_loss\"]) + 1)\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    # Plot loss\n",
    "    axes[0].plot(epochs, results[\"train_loss\"], label=\"Train Loss\")\n",
    "    axes[0].plot(epochs, results[\"test_loss\"], label=\"Test Loss\")\n",
    "    axes[0].set_xlabel(\"Epoch\")\n",
    "    axes[0].set_ylabel(\"Loss\")\n",
    "    axes[0].set_title(\"Loss Curves\")\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(True)\n",
    "    \n",
    "    # Plot accuracy\n",
    "    axes[1].plot(epochs, results[\"train_acc\"], label=\"Train Accuracy\")\n",
    "    axes[1].plot(epochs, results[\"test_acc\"], label=\"Test Accuracy\")\n",
    "    axes[1].set_xlabel(\"Epoch\")\n",
    "    axes[1].set_ylabel(\"Accuracy\")\n",
    "    axes[1].set_title(\"Accuracy Curves\")\n",
    "    axes[1].legend()\n",
    "    axes[1].grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Plot the loss curves\n",
    "plot_loss_curves(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyzing the Loss Curves\n",
    "\n",
    "From the plots, we can see:\n",
    "\n",
    "1. **Both losses are decreasing**: The model is learning!\n",
    "2. **Losses are converging**: Train and test loss are close, no major overfitting\n",
    "3. **Accuracy is increasing**: Both train and test accuracy improving\n",
    "4. **Fast convergence**: Good results after just 5 epochs\n",
    "\n",
    "This is the ideal scenario for transfer learning — the pretrained features provide such a good starting point that we converge quickly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Make Predictions on Test Set\n",
    "\n",
    "Let's visualize our model's predictions on some test images. This helps us qualitatively assess:\n",
    "- How confident is the model?\n",
    "- What kinds of images does it get right/wrong?\n",
    "\n",
    "### Create Prediction Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_and_plot_image(model: nn.Module,\n",
    "                        image_path: str,\n",
    "                        class_names: List[str],\n",
    "                        image_size: Tuple[int, int] = (224, 224),\n",
    "                        transform: torchvision.transforms = None,\n",
    "                        device: torch.device = device):\n",
    "    \"\"\"\n",
    "    Makes a prediction on an image and plots it with the prediction.\n",
    "    \"\"\"\n",
    "    # Open image\n",
    "    img = Image.open(image_path)\n",
    "    \n",
    "    # Create transform if not provided\n",
    "    if transform is not None:\n",
    "        image_transform = transform\n",
    "    else:\n",
    "        image_transform = transforms.Compose([\n",
    "            transforms.Resize(image_size),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225]),\n",
    "        ])\n",
    "    \n",
    "    # Make prediction\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.inference_mode():\n",
    "        # Transform and add batch dimension\n",
    "        transformed_image = image_transform(img).unsqueeze(dim=0)\n",
    "        \n",
    "        # Make prediction\n",
    "        target_image_pred = model(transformed_image.to(device))\n",
    "    \n",
    "    # Convert logits to probabilities\n",
    "    target_image_pred_probs = torch.softmax(target_image_pred, dim=1)\n",
    "    \n",
    "    # Get predicted label\n",
    "    target_image_pred_label = torch.argmax(target_image_pred_probs, dim=1)\n",
    "    \n",
    "    # Plot image with prediction\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.imshow(img)\n",
    "    plt.title(f\"Pred: {class_names[target_image_pred_label]} | Prob: {target_image_pred_probs.max():.3f}\")\n",
    "    plt.axis(False)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict on Random Test Images\n",
    "\n",
    "Let's select some random images from the test set and see how our model performs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a list of all test image paths\n",
    "test_image_paths = list(Path(test_dir).glob(\"*/*.jpg\"))\n",
    "print(f\"Total test images: {len(test_image_paths)}\")\n",
    "\n",
    "# Randomly select 3 images\n",
    "random.seed(42)\n",
    "sample_image_paths = random.sample(test_image_paths, k=3)\n",
    "\n",
    "# Make predictions on each\n",
    "for image_path in sample_image_paths:\n",
    "    pred_and_plot_image(\n",
    "        model=model,\n",
    "        image_path=image_path,\n",
    "        class_names=class_names,\n",
    "        transform=auto_transforms\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Multiple Predictions\n",
    "\n",
    "Let's create a grid of predictions to see more results at once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_and_plot_grid(model: nn.Module,\n",
    "                          test_dir: Path,\n",
    "                          class_names: List[str],\n",
    "                          transform,\n",
    "                          n_images: int = 9,\n",
    "                          device: torch.device = device):\n",
    "    \"\"\"Predicts on multiple images and plots them in a grid.\"\"\"\n",
    "    \n",
    "    # Get random image paths\n",
    "    test_image_paths = list(test_dir.glob(\"*/*.jpg\"))\n",
    "    sample_paths = random.sample(test_image_paths, k=n_images)\n",
    "    \n",
    "    # Setup plot\n",
    "    n_cols = 3\n",
    "    n_rows = (n_images + n_cols - 1) // n_cols\n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(12, n_rows * 4))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    for i, image_path in enumerate(sample_paths):\n",
    "        # Load and transform image\n",
    "        img = Image.open(image_path)\n",
    "        img_transformed = transform(img).unsqueeze(0).to(device)\n",
    "        \n",
    "        # Predict\n",
    "        with torch.inference_mode():\n",
    "            pred_logits = model(img_transformed)\n",
    "            pred_probs = torch.softmax(pred_logits, dim=1)\n",
    "            pred_label = torch.argmax(pred_probs, dim=1).item()\n",
    "            pred_prob = pred_probs.max().item()\n",
    "        \n",
    "        # Get true label from path\n",
    "        true_label = image_path.parent.name\n",
    "        \n",
    "        # Plot\n",
    "        axes[i].imshow(img)\n",
    "        \n",
    "        # Color title based on correctness\n",
    "        pred_class = class_names[pred_label]\n",
    "        color = \"green\" if pred_class == true_label else \"red\"\n",
    "        axes[i].set_title(f\"Pred: {pred_class} ({pred_prob:.2f})\\nTrue: {true_label}\", color=color)\n",
    "        axes[i].axis(\"off\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Plot predictions grid\n",
    "random.seed(123)  # Different seed for variety\n",
    "predict_and_plot_grid(\n",
    "    model=model,\n",
    "    test_dir=test_dir,\n",
    "    class_names=class_names,\n",
    "    transform=auto_transforms,\n",
    "    n_images=9\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Green titles indicate correct predictions, red titles indicate incorrect predictions. The model should get most of these right!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Make Predictions on Custom Images\n",
    "\n",
    "The real test of a model is predicting on completely new data — images it's never seen before.\n",
    "\n",
    "Let's download a custom image and test our model on it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download a custom image\n",
    "custom_image_path = data_path / \"pizza-dad.jpeg\"\n",
    "\n",
    "if not custom_image_path.is_file():\n",
    "    with open(custom_image_path, \"wb\") as f:\n",
    "        request = requests.get(\"https://github.com/poridhiEng/lab-asset/blob/main/tensorcode/Deep-learning-with-pytorch/Transfer-learning-with-pytorch/Lab_02/images/image-1.png?raw=true\")\n",
    "        print(f\"Downloading {custom_image_path}...\")\n",
    "        f.write(request.content)\n",
    "else:\n",
    "    print(f\"{custom_image_path} already exists.\")\n",
    "\n",
    "# Predict on custom image\n",
    "pred_and_plot_image(\n",
    "    model=model,\n",
    "    image_path=custom_image_path,\n",
    "    class_names=class_names,\n",
    "    transform=auto_transforms\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model correctly identifies the pizza in the image! And notice the high confidence — this is much better than our TinyVGG model which had lower confidence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Save the Trained Model\n",
    "\n",
    "Let's save our trained model so we can use it later without retraining."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create models directory\n",
    "MODEL_PATH = Path(\"models\")\n",
    "MODEL_PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Define model save path\n",
    "MODEL_NAME = \"efficientnet_b0_pizza_steak_sushi.pth\"\n",
    "MODEL_SAVE_PATH = MODEL_PATH / MODEL_NAME\n",
    "\n",
    "# Save the model state dict\n",
    "torch.save(obj=model.state_dict(), f=MODEL_SAVE_PATH)\n",
    "\n",
    "print(f\"Model saved to: {MODEL_SAVE_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Model (Verification)\n",
    "\n",
    "Let's verify we can load the model back correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new model instance\n",
    "loaded_model = torchvision.models.efficientnet_b0(weights=None)  # No pretrained weights\n",
    "\n",
    "# Modify the classifier (same as before)\n",
    "loaded_model.classifier = nn.Sequential(\n",
    "    nn.Dropout(p=0.2, inplace=True),\n",
    "    nn.Linear(in_features=1280, out_features=len(class_names), bias=True)\n",
    ")\n",
    "\n",
    "# Load the saved state dict\n",
    "loaded_model.load_state_dict(torch.load(MODEL_SAVE_PATH))\n",
    "loaded_model = loaded_model.to(device)\n",
    "\n",
    "print(\"Model loaded successfully!\")\n",
    "\n",
    "# Verify by making a prediction\n",
    "loaded_model.eval()\n",
    "with torch.inference_mode():\n",
    "    img = Image.open(custom_image_path)\n",
    "    img_transformed = auto_transforms(img).unsqueeze(0).to(device)\n",
    "    pred = loaded_model(img_transformed)\n",
    "    pred_class = class_names[torch.argmax(pred, dim=1).item()]\n",
    "    \n",
    "print(f\"Loaded model prediction: {pred_class}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Compare Results: Transfer Learning vs From Scratch\n",
    "\n",
    "Let's summarize the comparison between training from scratch and transfer learning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final summary\n",
    "print(\"=\"*60)\n",
    "print(\"COMPARISON: Transfer Learning vs Training From Scratch\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nDataset: Pizza, Steak, Sushi ({len(train_dataset)} train, {len(test_dataset)} test)\")\n",
    "print(f\"Epochs: {NUM_EPOCHS}\")\n",
    "print()\n",
    "print(\"+\" + \"-\"*58 + \"+\")\n",
    "print(f\"| {'Metric':<25} | {'TinyVGG':<12} | {'EfficientNet_B0':<12} |\")\n",
    "print(\"+\" + \"-\"*58 + \"+\")\n",
    "print(f\"| {'Test Accuracy':<25} | {'~40%':<12} | {'~' + str(int(results['test_acc'][-1]*100)) + '%':<12} |\")\n",
    "print(f\"| {'Parameters Trained':<25} | {'8,083':<12} | {'3,843':<12} |\")\n",
    "print(f\"| {'Total Parameters':<25} | {'8,083':<12} | {'~5.3M':<12} |\")\n",
    "print(f\"| {'Pretrained':<25} | {'No':<12} | {'Yes (ImageNet)':<12} |\")\n",
    "print(\"+\" + \"-\"*58 + \"+\")\n",
    "print()\n",
    "print(\"Key Insight: Transfer learning achieves 2x+ accuracy while\")\n",
    "print(\"training fewer parameters, thanks to pretrained features!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this lab, we:\n",
    "\n",
    "1. **Set up training components** — CrossEntropyLoss and Adam optimizer\n",
    "2. **Created training and testing functions** — Reusable step functions\n",
    "3. **Trained for 5 epochs** — Achieved ~85%+ test accuracy\n",
    "4. **Plotted loss curves** — Visualized training progress\n",
    "5. **Made predictions on test images** — Model works well on unseen data\n",
    "6. **Predicted on custom images** — Works on real-world photos\n",
    "7. **Saved the trained model** — For future use\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "1. **Transfer learning is incredibly powerful**: ~85%+ accuracy vs ~40% from scratch\n",
    "2. **Less training required**: Only 3,843 parameters trained, fast convergence\n",
    "3. **Works with small datasets**: The pretrained features generalize well\n",
    "4. **Easy to implement**: Just freeze layers and modify classifier\n",
    "\n",
    "### What's Next?\n",
    "\n",
    "You can extend this work by:\n",
    "- Training for more epochs\n",
    "- Using a larger EfficientNet (B1, B2, etc.)\n",
    "- Fine-tuning the entire model (unfreezing some base layers)\n",
    "- Adding data augmentation\n",
    "- Trying on your own custom dataset"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
